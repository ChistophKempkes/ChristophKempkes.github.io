---
title: Mein erster Post
date: 2024-03-24 13:13:00 +/-TTTT
categories: [Maschinelles Lernen]
tags: [ML, DL, AI]     # TAG names should always be lowercase
toc: false
---

# Theorie und Formeln hinter dem Entscheidungsbaum

In den letzten beiden Artikeln haben wir gelernt, wie Entscheidungsbäume und Random Forests programmiert werden können. In diesem Artikel soll es um die Theorie dahinter gehen. Doch zunächst eine kleine Wiederholung.

Entscheidungsbäume sind ein bekanntes Modell im maschinellen Lernen und werden oft für Klassifikations- und Regressionsprobleme verwendet. Sie stellen eine Hierarchie von Entscheidungen und Vorhersagen dar, die auf bestimmten Merkmalen und Regeln basieren.

Bei einem Random Forest wiederum handelt es sich um mehrere unkorrelierte Entscheidungsbäume, die während des Lernprozesses unter einer bestimmten Randomisierung entstanden sind und mit zufälligen Untermengen der Ausgangsdaten trainiert wurden. Die endgültige Vorhersage des Modells wird durch die Abstimmung der Vorhersagen aller Entscheidungsbäume ermittelt.

Doch nun zu den Konzepten und der Theorie hinter den Entscheidungsbäumen und somit letztlich auch den Random Forests.